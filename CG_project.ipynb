{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShamaLopes10/RealTime-Face-Detection-System/blob/main/CG_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 # OpenCV for image processing and Haar Cascade\n",
        "from google.colab import drive # For Google Drive access\n",
        "from google.colab import files # For uploading files (alternative to Drive)\n",
        "from google.colab.patches import cv2_imshow # For displaying OpenCV images in Colab\n",
        "from IPython.display import display, Javascript, Image # For webcam interaction\n",
        "from base64 import b64decode, b64encode # For webcam data encoding/decoding\n",
        "from google.colab.output import eval_js # For executing JS and getting results\n",
        "\n",
        "# --- Configuration ---\n",
        "IMG_WIDTH, IMG_HEIGHT = 48, 48\n",
        "NUM_CLASSES = 7 # Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral\n",
        "EMOTION_LABELS = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 60 # Adjust as needed, EarlyStopping will often stop it sooner\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"OpenCV Version:\", cv2.__version__)\n",
        "print(\"Setup cell executed.\")\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Define Path to your fer2013.csv file on Google Drive ---\n",
        "# !!! IMPORTANT: ADJUST THIS PATH if your file is located elsewhere in your Drive !!!\n",
        "FER2013_CSV_PATH = '/content/fer2013.csv'\n",
        "\n",
        "# --- Load Data ---\n",
        "try:\n",
        "    df = pd.read_csv(FER2013_CSV_PATH)\n",
        "    print(f\"Successfully loaded dataset from: {FER2013_CSV_PATH}\")\n",
        "    print(\"Dataset shape:\", df.shape)\n",
        "    print(\"First 5 rows:\\n\", df.head())\n",
        "\n",
        "    # --- CRITICAL CHECK: 'Usage' column distribution ---\n",
        "    if 'Usage' in df.columns:\n",
        "        print(\"\\nDistribution of 'Usage' column:\")\n",
        "        print(df['Usage'].value_counts())\n",
        "        if 'PublicTest' not in df['Usage'].value_counts() or df['Usage'].value_counts()['PublicTest'] == 0:\n",
        "            print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "            print(\"CRITICAL WARNING: 'PublicTest' usage category is missing or has 0 samples.\")\n",
        "            print(\"Validation data will be empty. Please check your fer2013.csv file.\")\n",
        "            print(\"Ensure it's the standard FER2013 dataset with 'Training', 'PublicTest', and 'PrivateTest' splits.\")\n",
        "            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
        "        if 'PrivateTest' not in df['Usage'].value_counts() or df['Usage'].value_counts()['PrivateTest'] == 0:\n",
        "            print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "            print(\"CRITICAL WARNING: 'PrivateTest' usage category is missing or has 0 samples.\")\n",
        "            print(\"Test data will be empty. Please check your fer2013.csv file.\")\n",
        "            print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
        "    else:\n",
        "        raise ValueError(\"'Usage' column not found in the CSV. Please check your fer2013.csv file.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(f\"CRITICAL ERROR: File not found at '{FER2013_CSV_PATH}'.\")\n",
        "    print(\"Please ensure the path is correct and the file exists in your Google Drive.\")\n",
        "    print(\"You might need to upload it or adjust the FER2013_CSV_PATH variable.\")\n",
        "    print(\"Stopping execution for this cell.\")\n",
        "    raise # Stop execution if file is not found\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the data: {e}\")\n",
        "    raise\n",
        "\n",
        "# --- Preprocessing Function ---\n",
        "def preprocess_data(dataframe, img_width=IMG_WIDTH, img_height=IMG_HEIGHT, num_classes=NUM_CLASSES):\n",
        "    if dataframe.empty:\n",
        "        print(\"Warning: Received an empty dataframe for preprocessing. Returning empty arrays.\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    for index, row in dataframe.iterrows():\n",
        "        pixels_str = row.get('pixels', '') # Use .get for safety\n",
        "        if not pixels_str:\n",
        "            print(f\"Warning: Empty pixel string for row {index}. Skipping.\")\n",
        "            continue\n",
        "        pixels = np.array(pixels_str.split(' '), dtype='float32')\n",
        "        if pixels.shape[0] != img_width * img_height:\n",
        "            print(f\"Warning: Incorrect number of pixels for row {index} (got {pixels.shape[0]}, expected {img_width*img_height}). Skipping.\")\n",
        "            continue\n",
        "        image = pixels.reshape((img_width, img_height))\n",
        "        images.append(image)\n",
        "        labels.append(row['emotion'])\n",
        "\n",
        "    if not images: # If all rows were skipped\n",
        "        print(\"Warning: No valid images found after parsing pixels. Returning empty arrays.\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    images_np = np.array(images)\n",
        "    labels_np = np.array(labels)\n",
        "\n",
        "    # Normalize images\n",
        "    images_np = images_np / 255.0\n",
        "\n",
        "    # Reshape for CNN (add channel dimension)\n",
        "    images_np = images_np.reshape(images_np.shape[0], img_width, img_height, 1)\n",
        "\n",
        "    # One-hot encode labels\n",
        "    labels_np = to_categorical(labels_np, num_classes=num_classes)\n",
        "\n",
        "    return images_np, labels_np\n",
        "\n",
        "# --- Split data based on 'Usage' column ---\n",
        "# Ensure df is not empty and 'Usage' column exists from checks above\n",
        "train_df = df[df['Usage'] == 'Training']\n",
        "val_df = df[df['Usage'] == 'PublicTest']\n",
        "test_df = df[df['Usage'] == 'PrivateTest']\n",
        "\n",
        "print(f\"\\nShape of train_df: {train_df.shape}\")\n",
        "print(f\"Shape of val_df (for validation): {val_df.shape}\")\n",
        "print(f\"Shape of test_df (for testing): {test_df.shape}\")\n",
        "\n",
        "# --- Process each split ---\n",
        "X_train, y_train = preprocess_data(train_df)\n",
        "X_val, y_val = preprocess_data(val_df)\n",
        "X_test, y_test = preprocess_data(test_df)\n",
        "\n",
        "print(f\"\\nProcessed X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"Processed X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"Processed X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "# --- CRITICAL CHECKS for processed data ---\n",
        "if X_train.shape[0] == 0:\n",
        "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(\"CRITICAL ERROR: Training data (X_train) is empty after preprocessing.\")\n",
        "    print(\"Cannot proceed with model training. Please check your CSV and preprocessing logic.\")\n",
        "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    # Consider raising an error here to stop execution if training data is vital\n",
        "if X_val.shape[0] == 0:\n",
        "    print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(\"WARNING: Validation data (X_val) is empty after preprocessing.\")\n",
        "    print(\"Validation will be skipped during training. Callbacks monitoring validation metrics may not work as expected.\")\n",
        "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
        "if X_test.shape[0] == 0:\n",
        "    print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(\"WARNING: Test data (X_test) is empty after preprocessing.\")\n",
        "    print(\"Final model evaluation on the test set will be skipped.\")\n",
        "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
        "\n",
        "\n",
        "# --- Visualize a sample image (if training data exists) ---\n",
        "if X_train.shape[0] > 0:\n",
        "    plt.imshow(X_train[0].reshape(IMG_WIDTH, IMG_HEIGHT), cmap='gray')\n",
        "    plt.title(f\"Sample - Emotion: {EMOTION_LABELS[np.argmax(y_train[0])]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Skipping sample image visualization as X_train is empty.\")\n",
        "\n",
        "print(\"\\nData loading and preprocessing cell executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "CGaaM0i5zr7m",
        "outputId": "9cb5fc73-f63c-4bb9-a6d3-c57133f66c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.18.0\n",
            "OpenCV Version: 4.11.0\n",
            "Setup cell executed.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Successfully loaded dataset from: /content/fer2013.csv\n",
            "Dataset shape: (35887, 3)\n",
            "First 5 rows:\n",
            "    emotion                                             pixels     Usage\n",
            "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
            "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
            "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
            "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
            "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
            "\n",
            "Distribution of 'Usage' column:\n",
            "Usage\n",
            "Training       28709\n",
            "PublicTest      3589\n",
            "PrivateTest     3589\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Shape of train_df: (28709, 3)\n",
            "Shape of val_df (for validation): (3589, 3)\n",
            "Shape of test_df (for testing): (3589, 3)\n",
            "\n",
            "Processed X_train shape: (28709, 48, 48, 1), y_train shape: (28709, 7)\n",
            "Processed X_val shape: (3589, 48, 48, 1), y_val shape: (3589, 7)\n",
            "Processed X_test shape: (3589, 48, 48, 1), y_test shape: (3589, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAL3JJREFUeJzt3X1w1eWZ//ErYpJDEhIIEMKTCQGUR9EqdWm1weKiLT5u7a7basF21Wkrs+N07e7a7YDttLKzU6FCZbTb0lZYx+paa3fFWrfUHYurnQqo1eWpghp5CIGQQIAIuX9/OLmHmHyvzyF3EH/b92umM+Vc5z7n+3TO5YHPfX8LQgjBAAAws9NO9QYAAD44aAoAgIimAACIaAoAgIimAACIaAoAgIimAACIaAoAgIimAACIaAo4IQUFBbZw4cJTvRkfeAsXLrSCgoJTvRnACaMpnAIvv/yyXXvttVZTU2O5XM5Gjhxpf/7nf25Lly491Zv2gTZz5kwrKCjo8X8TJkx437enra3NFi5caL/5zW/e9/dO8cQTT1hBQYGNGDHCOjo6TvXm4APm9FO9AX9q1q5daxdffLGdccYZdtNNN1l1dbW9+eab9j//8z/23e9+1+bPn3+qN/EDbdSoUXbXXXd1e7yiouJ935a2tja78847zezdhnW8f/qnf7J/+Id/eN+3KR+rVq2y2tpa27Ztm/3617+2Sy655FRvEj5AaArvs29961tWUVFhv/vd72zgwIFdart37z41G/X/kYqKCrv++utP9WZIp59+up1++gfv43Xw4EH7+c9/bnfddZetWLHCVq1adcqaQkdHh7W3t1sulzsl74+e8ddH77OtW7fa5MmTuzUEM7Oqqqouf16xYoV9/OMft6qqKisuLrZJkybZ8uXLu42rra21yy+/3H7zm9/Y+eefb/3797epU6fGv9Z49NFHberUqZbL5ey8886zdevWdRk/b948Kysrsz/+8Y926aWXWmlpqY0YMcK+8Y1vWD6L6DY0NNjnP/95GzZsmBUXF9vkyZPthz/8Yf4HpY91/n3+pk2b7Prrr7eKigobOnSoff3rX7cQgr355pt21VVXWXl5uVVXV9t3vvOdbq+xe/du+8IXvmDDhg2zXC5n06ZNsx//+Mexvm3bNhs6dKiZmd15553xr7E6/72lp39TOHr0qH3zm9+0sWPHWnFxsdXW1todd9xhR44c6fK8zvP57LPP2oc//GHL5XJWV1dnP/nJT7pt59atW23r1q15H5uf/exndujQIfv0pz9t1113nT366KN2+PDhbs8rKCiwW2+91R577DGbMmVKPK9PPvlkt+d2Xne5XM7Gjh1r9913X4/73/maq1atssmTJ1txcbGtXr3aamtr7aqrrur2uocPH7aKigq75ZZb8t4/9IGA99Xs2bPDgAEDwssvvyyfO3369DBv3rywePHisHTp0jB79uxgZmHZsmVdnldTUxPOOuusMHz48LBw4cKwePHiMHLkyFBWVhZWrlwZzjjjjLBo0aKwaNGiUFFREcaNGxeOHTsWx8+dOzfkcrkwfvz4cMMNN4Rly5aFyy+/PJhZ+PrXv97lvcwsLFiwIP55586dYdSoUWH06NHhG9/4Rli+fHm48sorg5mFxYsXJx2r96qvrw8TJkwIjY2N3f534MCB+LwFCxYEMwvnnHNO+Ou//utw7733hjlz5gQzC3fffXc466yzwhe/+MVw7733ho9+9KPBzMIzzzwTx7e1tYWJEyeGwsLCcNttt4V77rknXHTRRcHMwpIlS0IIIRw4cCAsX748mFm45pprwgMPPBAeeOCBsGHDhi7bcLy5c+cGMwvXXntt+N73vhc+97nPBTMLV199dZfndZ7PYcOGhTvuuCMsW7YsfOhDHwoFBQXhlVde6fbcmpqavI/hZZddFmbNmhVCCGH79u2hoKAg/PSnP+32PDML06ZNC8OHDw/f/OY3w5IlS0JdXV0oKSkJe/bsic978cUXQ3FxcaitrQ2LFi0K3/rWt8KIESPCtGnTuu2/mYWJEyeGoUOHhjvvvDN873vfC+vWrQtf+9rXQmFhYWhqaury/J/+9KfBzMJ///d/571/SEdTeJ899dRToV+/fqFfv35hxowZ4atf/Wr45S9/Gdrb27s9t62trdtjl156aairq+vyWE1NTTCzsHbt2vjYL3/5y2BmoX///mH79u3x8fvuuy+YWVizZk18rPPLav78+fGxjo6OMGfOnFBUVBQaGxvj4+9tCl/4whfC8OHDu3xRhBDCddddFyoqKnrch96qr68PZtbj/2655Zb4vM4v5Jtvvjk+dvTo0TBq1KhQUFAQFi1aFB/ft29f6N+/f5g7d258bMmSJcHMwsqVK+Nj7e3tYcaMGaGsrCy0tLSEEEJobGzsdjzeuw2d1q9fH8ws/M3f/E2X5/3d3/1dMLPw61//Oj7WeT6P/zLcvXt3KC4uDl/5yle6jD+RprBr165w+umnh+9///vxsY985CPhqquu6vZcMwtFRUVhy5Yt8bENGzYEMwtLly6Nj11xxRWhpKQkNDQ0xMc2b94cTj/99B6bwmmnnRb+8Ic/dHl848aNwczC8uXLuzx+5ZVXhtra2tDR0ZHX/qFv0BROgRdeeCFcc801oaSkJH6pDR06NPz85z/PHNPc3BwaGxvDt7/97WBmobm5OdZqamrCpEmTuj3fzMKcOXO6PN755fSDH/wgPtbZFDZu3NjluatXrw5mFh588MH42PFfgh0dHWHgwIHh5ptv7vZf7itWrAhmFp599tkTPj5Z6uvrQ21tbfjVr37V7X+vvfZafF7nF/ILL7zQZfzVV18dzKxLkwshhHPOOSdcdNFF8c+zZ88O1dXVXX5NhRDCgw8+GMws/OIXvwghnFhT6Dxvr776apfn7dixI5hZly/7ns5nCCGcffbZ4Zprrsk6PNJ3v/vdUFRUFPbu3RsfW7p0abfHQnj3PH/yk5/s9hrl5eXhtttuCyG822j79+8fPvOZz3R73hVXXNFjU7j44ot73LYLLrggXHjhhfHPTU1NobCwMHzta1/LfwfRJz54/xL2J2D69On26KOPWnt7u23YsMF+9rOf2eLFi+3aa6+19evX26RJk8zM7Le//a0tWLDAnnvuOWtra+vyGvv37++SuDnjjDO61Dtro0eP7vHxffv2dXn8tNNOs7q6ui6PnXnmmWb27t+f96SxsdGam5vt/vvvt/vvv7/H53j/eL53715rb2+Pf+7fv79MEZWWlub9D6M9HZNcLmdDhgzp9nhTU1P88/bt2238+PF22mld/8lt4sSJsX6itm/fbqeddpqNGzeuy+PV1dU2cODAbq/53m03Mxs0aFC383YiVq5caR/+8Ietqakp7u+5555r7e3t9vDDD9vNN998Qtuwe/duO3ToULd9MrMeHzMzGzNmTI+Pf+5zn7Nbb73Vtm/fbjU1Nfbwww/bO++8YzfccMMJ7SPS0RROoaKiIps+fbpNnz7dzjzzTLvxxhvt4YcftgULFtjWrVtt1qxZNmHCBLv77rtt9OjRVlRUZE888YQtXry4W768X79+Pb5H1uOhD+7C2rkN119/vc2dO7fH55x99tmZ4//iL/7CnnnmmfjnuXPn2o9+9KPk7erU076fzOORj3wntPX1dm7evNl+97vfmZnZ+PHju9VXrVrVrSmcjGPVv3//Hh+/7rrr7LbbbrNVq1bZHXfcYStXrrTzzz/fzjrrrF6/F3qHpvABcf7555uZ2Y4dO8zM7Be/+IUdOXLEHn/88S7/xbZmzZqT8v4dHR32xz/+Mf46MDPbtGmTmb2bhunJ0KFDbcCAAXbs2LFexRq/853vdPkv3xEjRpzwa5wMNTU19tJLL1lHR0eXXwv/+7//G+tm+X/Bd47p6OiwzZs3x18cZma7du2y5ubm+Jony6pVq6ywsNAeeOCBbl/2zz77rN1zzz32xhtv9PjrIEtVVZXlcjnbsmVLt1pPj3kqKyttzpw5tmrVKvvsZz9rv/3tb23JkiUn9BroG0RS32dr1qzp8b+0nnjiCTOz+F9GnR/c45+7f/9+W7FixUnbtmXLlsX/H0KwZcuWWWFhoc2aNavH5/fr188+9alP2b//+7/bK6+80q3e2Njovt95551nl1xySfxf51+bnWqf/OQnbefOnfbQQw/Fx44ePWpLly61srIyq6+vNzOzkpISMzNrbm7O6zXNrNsX3d13321mZnPmzOnVtuYbSV21apVddNFF9ld/9Vd27bXXdvnf7bffbmZmDz744Am9d79+/eySSy6xxx57zN5+++34+JYtW2z16tUntiNmdsMNN9irr75qt99+u/Xr18+uu+66E34NpOOXwvts/vz51tbWZtdcc41NmDDB2tvbbe3atfbQQw9ZbW2t3XjjjWZmNnv2bCsqKrIrrrjCbrnlFjtw4IB9//vft6qqqvhroi/lcjl78sknbe7cuXbBBRfY6tWr7T//8z/tjjvuiHn8nixatMjWrFljF1xwgd100002adIk27t3r7344ov29NNP2969e/t0O/fv328rV67ssdZXk9puvvlmu++++2zevHn2+9//3mpra+2RRx6J//U6YMAAM3v3r0ImTZpkDz30kJ155plWWVlpU6ZMsSlTpnR7zWnTptncuXPt/vvvt+bmZquvr7cXXnjBfvzjH9vVV19tF198ca+2tbNhZ/27j5nZ888/b1u2bLFbb721x/rIkSPtQx/6kK1atcr+/u///oTef+HChfbUU0/ZRz/6UfviF79ox44ds2XLltmUKVNs/fr1J/Rac+bMscGDB9vDDz9sn/jEJ7rN28H75BT+I/efpNWrV4fPf/7zYcKECaGsrCwUFRWFcePGhfnz54ddu3Z1ee7jjz8ezj777JDL5UJtbW3453/+5/DDH/4wmFl4/fXX4/Nqamq6pYxCeDft8eUvf7nLY6+//nows/Av//Iv8bG5c+eG0tLSsHXr1jB79uxQUlIShg0bFhYsWNAtgWM9pG127doVvvzlL4fRo0eHwsLCUF1dHWbNmhXuv//+Xh6lnnmR1OMv5c7kz3tTRp372dPrTp48uds+3XjjjWHIkCGhqKgoTJ06NaxYsaLb2LVr14bzzjsvFBUVdTk2Pc1TeOedd8Kdd94ZxowZEwoLC8Po0aPDP/7jP4bDhw93eV7W+ayvrw/19fXdnqsiqfPnzw9mFrZu3Zr5nIULFwYzi/Mserp2Ot/v+PhuCCH813/9Vzj33HNDUVFRGDt2bPjXf/3X8JWvfCXkcrkuz8t6zeN96UtfCmYW/u3f/s19Hk6eghDep39hwwfWvHnz7JFHHrEDBw6c6k3B/xFXX321/eEPf7DNmzef0LjbbrvNfvCDH9jOnTvjX8/h/cW/KQBIcujQoS5/3rx5sz3xxBPdFglUDh8+bCtXrrRPfepTNIRTiH9TAJCkrq7O5s2bZ3V1dbZ9+3Zbvny5FRUV2Ve/+tW8xu/evduefvppe+SRR6ypqcn+9m//9iRvMTw0BQBJLrvsMnvwwQdt586dVlxcbDNmzLBvf/vbPc6H6Mmrr75qn/3sZ62qqsruueceO+ecc07uBsPFvykAACL+TQEAENEUAABR3v+mcPnll7v1zgk9PclaQ6VTa2urW0+ZAKXe+72Lnr3XexeiO15hYWHSe3szYadPn+6OzVpYrJO6m9WxY8cya++884479vhF7Hri7dd7kyonWle8/S4rK3PHlpeXu/X3LqR3PDXRyvt8mJkVFxe79Z5uytRJ3WdZ3QHu6NGjmTV1LWzYsMGt79y5s9fb1dPNf463f/9+t+7NqFcLC6r99q5T9blX3xsqGu7V1bWwceNGt27GLwUAwHFoCgCAiKYAAIhoCgCAiKYAAIhoCgCAiKYAAIjynqegsuleHtnLQZvpe756mXqzd28mnkXl9dV+eVlqNb9CZZ0/8YlPZNbUPAW1iqQ65p6ioqJejzUzO3LkSGYtZbvM9LwSLwOurgW13948BzU2ta7226Ny897ny5unY2Z27rnnunXv9rENDQ3uWHWNq2Pi7Ze6FtRn16Nu06rm4qj5G951qM5XPvilAACIaAoAgIimAACIaAoAgIimAACIaAoAgCjvSGpTU5Nb96JQFRUV7li1rLCKpHoRLrX8roqeectAV1ZWumMvueQSt+7ddlBFFFXMMIVa2ldF7rxtS33tlPdOibOquooRpp5Pb79VpFsdMy8mrPZLfXa9W3KqZZzV+VDRTm9pbRXdVPvtHXO1XSrKrqK4XpxWbXc++KUAAIhoCgCAiKYAAIhoCgCAiKYAAIhoCgCAiKYAAIjyDrV6eX0zPzurcrcHDhxIqnu535T8t5nZhAkTMmuXXnqpO7a6utqte7n51Fy7Gt/R0dHr11Z1lS/3qPOh5hp4Oe3Ua8Gjtku9t8qXe+dLzeNR711cXNzr7VJzJCZOnJhZe+qpp9yx6jvHW0LazJ8voM61Oqbe3A71faWW61dSroV88EsBABDRFAAAEU0BABDRFAAAEU0BABDRFAAAEU0BABDlPU/By8aa+dlctXa5uudBeXm5W/cy4mrs1KlT3frHPvaxzNqwYcN6vV2KyhunzEMw87ctdZ5CytiUY6ZeX2XTU+ZXqP1KuSeImX9c+mIN/Sxqv7y8vpnZ0KFDM2sjRoxwx/7+97936yNHjnTr3r0e9u3b54715l2lUq89cOBAt+7NDVH3asgHvxQAABFNAQAQ0RQAABFNAQAQ0RQAABFNAQAQ0RQAAFGf3U/BW5NdZc8HDx7s1r2ss5k/F2Hs2LHu2GnTprn10tJSt+5RGW+1Fn0Kdcy9eQwpcxzM/Ey+mivgXUdmJ/eYnUpqjX3vmKvzkTr3I0X//v0za3V1de7Yp59+2q2rTH5NTU1mraWlxR2rrlPvs62uYTUva8+ePW69oqIis6Y+u/nglwIAIKIpAAAimgIAIKIpAAAimgIAIKIpAACiPltz14thVVVVuWO9JW7N9FKyZ555ZmattrbWHetF5sz8CKSKR6q6F3tTyyGryJyqp8QU1Wt7UiOlKdudsjy1mb/f6piknk+PiiGmXqcny5gxY9y6im7u2LHDrXtxcrWkvoq7pixlPmjQILfe1NTk1g8dOpRZ64tzyS8FAEBEUwAARDQFAEBEUwAARDQFAEBEUwAARDQFAECU9zwFtQz0O++8k1k7evSovxEi16uWzvaW3lbL2Kr98paBVjlqlT0vLCzs9VhFHXMvz1xUVJT03ieTymF75ys1r5/y2t65NjPL5XJuXX1GUnifAXUdqTkS3vjq6mp3rDomjY2Nbt3bNi/rb6a/F7z9UsdEXQtqXpa3bWp+RT74pQAAiGgKAICIpgAAiGgKAICIpgAAiGgKAICIpgAAiPIOP3vzEMz87K3K7aoMdkVFhVv3cvVqjXyVL/fGe7l1Mz2PwRuvsswpa/+b+Tnr1HklXo46de1/dVy88eqYqDkt3vlS14I6Zio371HXgtovb7waq74X2tvbM2tqHoK6z8rbb7/t1r28v/pspsxvSrnnh5k+Lt61oj67+eCXAgAgoikAACKaAgAgoikAACKaAgAgoikAAKK8I6kqcqeigp7y8nK3Xlpa2uu6WgI3Zenf1OiZd0xTYp/5jPfimSpmqKhInae5uTnptb1zkhp39epHjhxxx6o4bElJiVv3rkO1X+oaV59tj7rOUq4l9fk6ePCgW/dipynXqJl/LaR+fhRvv9S5zge/FAAAEU0BABDRFAAAEU0BABDRFAAAEU0BABDRFAAAUd7zFFSu11tqtrKy0h2r6oMGDXLrKivtURlvr67Gqmy6l8NWeWOVhU7JK6uxra2tbr2trS2zppZDVsd03759bt27DtVcAvXew4YNy6yp/fKWkDbT10oKNafFq6s5DClLNavtUsdM1T2pS0x78xTUfBe13+qYe9e4uobzwS8FAEBEUwAARDQFAEBEUwAARDQFAEBEUwAARDQFAEDUZ/MUBg8enFkbP368O3bUqFFuXa01r3K/HpUJTnltlaP2su39+/d3x6rtSrnvgKKy0IcOHcqsqbkCartSMuBqrDe/wsxfx16djwMHDrj1oqIit+5dK+o687bbzM/sqzkr6nx5r63m2qjzoeYneedbfb7Ue3vUnBM1RyJlv7ifAgCgT9EUAAARTQEAENEUAAARTQEAENEUAABR3pFUL3JqZlZbW5tZq6urc8eqpbNVvDJl6WwVD/PqKo6nYopedE1FZVVdRdO8SF7Kkt9mZhUVFW7do2KK3rLBZjpq6GlqanLr+/fvz6ypqK16bXU+vc+AWrZbvbZ3zFMi2eq99+7d6471jreZ/l7wYqXqGk5ZylxFttX5UPFk7/VToubxNZJfAQDwfwZNAQAQ0RQAABFNAQAQ0RQAABFNAQAQ0RQAAFHeAf/q6mq3XlNTk1kbOnSoO1blctU8BC+bq/L6KjPsLTus8shqv3bt2pVZU0ste8tTm+m8v5fDHjJkiDtWLWXuzVMoLy93x6pjpt7be321dLbKeLe2tmbWWlpa3LGqro5LQ0NDZk3NISorK3Pr3twONU9BLcvtjfeOp5k+1ylLhqtrQX3neJ999Z2ipM5zSMUvBQBARFMAAEQ0BQBARFMAAEQ0BQBARFMAAEQ0BQBA1Gf3Uxg0aFBmTa2BrzLDipcpVvMU1Dr4Xt4/dS6Bt8a+Wkte5fnVevBe1nnPnj29Hmvm58/Vdql8+KhRo9y6NydG3Xdg4MCBbt3bdpUtV3l/b+1/M//eA+q1U+6noOY4qP32jlnqnBT12fXmMaTcg8XMv89KyjFJlbpfZvxSAAAch6YAAIhoCgCAiKYAAIhoCgCAiKYAAIhoCgCAKO9Qa2lpqVv31mRX69SrnHVKrle9tuKtya7mEqjsuTeHwjueZmnZc1Vvbm52xx48eNCte/Mc1Pr7uVzOrb/11lu9Hp8y18bMbPTo0b0eq+4pos6Xdz8GNV9GzRPy8vxqLoGax5AyB0l95+zbt8+te3MJvJpZ2v0UlJSxZv73ofquzQe/FAAAEU0BABDRFAAAEU0BABDRFAAAEU0BABDlHUlV0TIvJuVF3vKhYnFefExFtNR+ea+t4pMqfulFN19//XV3rIrpqtibivN5VNRWHRePF70001HCioqKzJo6HypqW15enllTy3KrJdxVDHjHjh2ZNbWEtIpOv/nmm5k1dR2p/faWOlexT1U/mVH11CXePSpOrt7b+3ypz0c++KUAAIhoCgCAiKYAAIhoCgCAiKYAAIhoCgCAiKYAAIjyDtuqpX29fKzKOqsMd8rS22qsyll741XWWeWRveWUVd5YLSvszYEw85egVudDLcX88Y9/PLOm5l80NTW5dXVMvfrAgQPdseqYevNl1FLn6rW3bdvm1p988snMmjpmal6Jd42rPP65557r1r39VteC+t5Q2+Z9Z6nrSH1veHU1z0B9vlKW1maeAgCgT9EUAAARTQEAENEUAAARTQEAENEUAAARTQEAEPXZPAUvCz1o0CB3rMoEp6xtrjL1KVlodS+GIUOGuHUv2759+3Z3rLpHhdo2Lyv9xhtvuGNnzJjh1i+88MLMmro3hsquq7y/d52OHDnSHVtZWenWhw8fnlmrqqpyx6pr4bHHHnPr69evz6wdOnTIHevNhzEzmzlzplv37N692617ufm9e/e6Y9VnU80T8q4FledXnx+P2i5F7XdfzEXw8EsBABDRFAAAEU0BABDRFAAAEU0BABDRFAAAUd6R1JaWFrd+5MiRzNrJXBrbLG1JY7X8rrfErlp2W0UFvejZiBEj3LGvvPKKW1f7/elPfzqzprZ78ODBbt07ZmPGjHHHjho1yq1XVFS4dW/J8NTlrb39VnFXFVlVUd3Ro0dn1pqbm92xytixYzNr55xzjjv2mWeeceteLPTAgQPuWBUnV1H1lGhoylgVKVXnOmXp7dQ4rBm/FAAAx6EpAAAimgIAIKIpAAAimgIAIKIpAAAimgIAIMp7nkJra6tb97LpatltNY9B5X69XK+ah5CShVbbrTLDhw8fzqypORCTJ09269u2bXPrO3bsyKyVlZW5Y5uamty6t+ywmmeg5gqo8+Ut066uI/Xa3tLaJSUl7tjy8nK3ftlll7l1b+lttXy1+gzU19e7dc+ll17q1jdt2pRZ865/M30tqM+X9510Mql5BmpZ7pTvO/Xe+eCXAgAgoikAACKaAgAgoikAACKaAgAgoikAACKaAgAgynuewttvv+3WDx48mFlLzROnzGNInUvgZYrVWJV799aTV8fEy+Ob6fsxePNOjh496o5NuT+GuneGyqarzL13Lwjvnh9m+nx592NQY1U2fdKkSW7d2y91Dwo172Tfvn2ZNXUPCnV/jHXr1mXWUucvpWTy1XWkpMyBUPutrpWUuVP54JcCACCiKQAAIpoCACCiKQAAIpoCACCiKQAAIpoCACDKO6yrstBenlmtD67y4yor7Y1XmV8118DLM6vMvVpj3xuv5gqo/VJ5Ze++BipHnZLRzuVybl1ttzou3rapc622rb29vVfva6avFXW/hbq6usxaQ0ODO7alpcWte7z7OJjp+TLee6tzqe63oM6nJ+WeBUrq/WFS9ksd03zwSwEAENEUAAARTQEAENEUAAARTQEAENEUAABR3pHUsWPHunUvNqqiZSoK6C0xbeYvW6wiWt6SxGZ+PExFy4qKity6F3dV261io2rbvPEqXqmWHfbqKVE/M31cvPOl9isliuvFVfN5b3VMBwwYkFmrrq52x9bW1rp175ykRLbN/POlroXUeKX3GUiJVSvqtdV+q/HeOVHR53zwSwEAENEUAAARTQEAENEUAAARTQEAENEUAAARTQEAEOU9TyFlmVs1FyA1M+y9vspRp7y3WiJXLQnuLa3tzb3I571V5t7LSqtluVOkLH1tpue8eONTj5l3TtR2q3kMijfnxZvDYGZ28ODBXr+2WrZeXSve+VZzINS1ovL+Xj11HpD6XvGo61C9tnctqflJ+eCXAgAgoikAACKaAgAgoikAACKaAgAgoikAACKaAgAgyjtsq3LzXj5WZX5T39ubp6Cy0CqH7e1XaibYy497cxjMdD5c3ctBHVNPan7co+6d0dra2uv3Vvlwtd1eflxd42qujroOPepaUNeStwa/uo5S7hOh8vip84BSrgX12e6L+xb09r1T7n+RD34pAAAimgIAIKIpAAAimgIAIKIpAAAimgIAIMo7kpqynLKKraVGBb3YnIpPqlhbSgxRxda8bVPbXVpa6tbVMfXGp8bavG1va2tzx+7fvz+p7i2trZaYVnXvWsjlcu5YdUxV9NOjop0pyzyra1h9BrxrISUCbKY/ux71+Uihvu/UtZAyvi+WveeXAgAgoikAACKaAgAgoikAACKaAgAgoikAACKaAgAg6n2A+T28zLHK3KtsbXt7u1v3liVW+XGVlU7JQquctZdNV9udkj0387PQaulelfH2zrc3j8DMrLm52a17y42bmVVWVmbWUpeY9pa3VvMMUuve9aCOqdpv7xpXx1t9Nr2l0FPnV6jl3733Tl0S3PuMpM7zUeO9uSFqu/PBLwUAQERTAABENAUAQERTAABENAUAQERTAABENAUAQJR32F2tq56yPrnK1qq6N0+hrKzMHavyyt5rp97zwJsjoTLa6nyo8V6+XOWk1bn2Xru1tdUdq+YpePMQVF1ttzpm3vlKuXeGmb7GvWvJy+Ob6f3ytk3dL6GxsdGt79mzp9fbpah5CinzBdRcHY+a+6SuBbXd3nFL2e5O/FIAAEQ0BQBARFMAAEQ0BQBARFMAAEQ0BQBARFMAAER5B4VVdtbL+6s8scqPn8z1+9Va89469inbZebnmb35Efm8dur6/Snv7a3B39TU5I5VufiUe2+ofVbvnXKdqXkMaq6Bmm/jUfvlzZFQmfvXX3/drbe1tWXW1PlQny91LXh1dR+IlGshdf6FOuYna2wnfikAACKaAgAgoikAACKaAgAgoikAACKaAgAg6rOls726ipapJaZT4pkqKuhFTs38eFlJSYk7Vi2H7MXH+mIJXE/K66s4nxdJVVE/tbR2Q0ODW/eulX379rlj1bUyYMCAzNrEiRPdsVVVVW7dO2Zmfqx7+PDh7lgVZz1y5EhmTV0nr732mlv3PpspsWiztCh7apxcfQZSnOzPvsIvBQBARFMAAEQ0BQBARFMAAEQ0BQBARFMAAEQ0BQBA1GdLZ3uZ+9RMsFoi18u+qzyxyqZ78xTUPAQ1t0Ptt0ctkave28tCq9dWx8w7LpWVle7YTZs2ufW1a9e69W3btmXWdu7c6Y5V+fBRo0Zl1jZs2OCOVedDZfbr6+t7tV1maUtnNzY2umM3b97s1r3PrvpeUOcj5TOglrdWr60++ylS5jep7+l88EsBABDRFAAAEU0BABDRFAAAEU0BABDRFAAAEU0BABDlPU8h5b4EKvOrctQq451CzRXw6mq7vTXwzfwctspoqyyzqnuvn5of9+47oF577Nixbl3l5r38+bhx49yx6p4Gzc3NmTV1z4/a2lq3ftFFF7l1by6CuoZT5imo+yV4x8TMPx/qO0Vl7tX8JW+8ug7V58fbL/XaqU7m96EZvxQAAMehKQAAIpoCACCiKQAAIpoCACCiKQAAorwjqSr2lrKUrIpYqXpfLBebxdtvtSy32i4v1qZivKmRVS82p15bRW379+/f6+0aOXKkW585c6Zb9yKrKjba2trq1vfs2ZNZU0uCX3jhhW594sSJbr2hoSGzpj6b6jr0orgvvfSSO1ZJWR4+lfcZSlmeOvW11flIXZI/Fb8UAAARTQEAENEUAAARTQEAENEUAAARTQEAENEUAABR3vMU1LLCXna2tLTUHauW9lVL5HpUpl7NNfB48wzMdJ7YyzqruQIqR52SD1f7pZYGPnLkSGZNZbBT58N4cyTKy8vdscOGDXPrVVVVvX5tdczUZ8DbL3XM1Odn48aNmbUtW7a4Y70l8838/U69hlOWzlafr5M59yllWe73A78UAAARTQEAENEUAAARTQEAENEUAAARTQEAENEUAABRnwVivUxx6nrvKfctUPlwNZfAG6/W3095b5VVVhltlYX25hKouR0tLS1u3btvQcrxNjNra2tz695+q+uoqKjIrXvnRJ2vw4cPu/Wmpia3XlZWlllT+6XuI7F27drMWur9ENT8C4+aS5BCXUfqWvDq6pipa0XN3/D0xb0W+KUAAIhoCgCAiKYAAIhoCgCAiKYAAIhoCgCAKO9IqhdhNPOjUCqWpiKQKh7mxRjVe6sIlxdxTF3a19tv9dpqu9V+e6+vzvX+/fvduhclVHE7VVdRWy+6qa4jFe30jrm3tLWZjiHu3bu31+NLSkrcsc8//7xb37ZtW2ZN7Ze6Vrzr0DtX+by2MmbMmMzaxIkT3bHbt29362+88UZmbcCAAe5Y9X2XGqNPxS8FAEBEUwAARDQFAEBEUwAARDQFAEBEUwAARDQFAECU9zwFtfxuitRcrldXSxar9/YyxSpTr947l8tl1tSywWq7VZ7fWzo49Vx750OdSzW3Q82/OHDgQGbNO95mZiNGjHDr3vlWx1udT3UteePVnJbnnnvOrXvHVM2vUMvee9vtnSszs3Hjxrn1s88+260PHTo0s/aZz3zGHavO169+9avM2r333uuO3bFjh1tXx/xk45cCACCiKQAAIpoCACCiKQAAIpoCACCiKQAAIpoCACDKOxB78ODBXr+JyoerddNVFtrLiKtcvFpjP+XeACo/7s0HUGuuqxy1ys1727Znzx53bGNjo1tvbW3NrLW0tLhjm5ub3XrKfSJU/nv8+PFu3buW1DU8Y8YMtz548OBe19966y13rHe/BDP/ngnqGlbno7q6OrM2bdo0d+xNN93k1l966SW3/sADD2TWLrzwQndseXm5W/+zP/uzzFplZaU7dsmSJW5dfUa87yw1Nyof/FIAAEQ0BQBARFMAAEQ0BQBARFMAAEQ0BQBARFMAAER5z1Pwsudmfp5ZZZnLysrcusque/cWUPMQVN3Lpqeue+4dF3XM1NwNlVf25lgMHz7cHavWwd++fXtmbd++fUmv7d0HQtVLSkrcsSrvP3DgwMxaRUWFO9Zb29/MrLS01K1753vdunXuWDXHyHtv9dn8y7/8S7f+sY99LLOmjok61+o7yft83nXXXe7YnTt3unVvbofar9GjR7v1hoaGXtcHDRrkjs0HvxQAABFNAQAQ0RQAABFNAQAQ0RQAABFNAQAQ5Z2pVEvoevExFd1U0TO1/LUXr9y/f3+vx5qlxV3Va3vjU5cTVwYMGJBZU8sGjxs3zq3PnDmzN5tkZvpcq3ilF19W16Haby92qpYqV0udq/3yorobNmxwxxYWFrp17xqfNWuWO/aCCy5w6975ePzxx92xar92797t1tvb2zNrKs7a1NTk1r14svrOUfFj77Np5l9LmzZtcsfmg18KAICIpgAAiGgKAICIpgAAiGgKAICIpgAAiGgKAIAo73kKailnL/erMvdqqdlcLufWvZy1ouYaeFTuXb22N9dALX2tjolaQtfLrqtzfejQIbfuHReV1/eWJDbTyw6PHz8+s1ZcXOyOVdeRmkvgUdeCWlLcy59v3LjRHauu06lTp2bW6urq3LFqu1977bXMmlqqXM0VUJ+RyspKt+5Rc4y87zt1javX9uZAmJldeeWVmTW15Hc++KUAAIhoCgCAiKYAAIhoCgCAiKYAAIhoCgCAiKYAAIjynqeQYu/evW5draGvcrteLljlw8vKyty6yux7VD7cyzqreQjqmKXMK1HUvTW8/Vb3gWhpaXHrb7/9tlv35lCo91bX2ZAhQzJran6FytSrz8hzzz2XWRs2bJg7Vu3X9OnTM2tqbX91TNU9ETyTJk1y61u2bHHr3ryS6upqd6y6J4L3nePdQ8JMz9tSn6/Jkydn1tS9TvLBLwUAQERTAABENAUAQERTAABENAUAQERTAABEeUdS1bLB3rLEKj6ZGln14ptqmWf12uXl5Zk1FXdta2tz6954tV2lpaVuXe33sWPHMmsqZqjild5yymqp5fb29qR6Q0NDZk1FBb1lt83MPvKRj2TWVCxUnc8XXnjBrb/44ouZtSlTprhjr7jiCrfuxTPVtaCuszfeeCOzpmLTavn3ESNGuHUv3tzY2OiOVefTi7J7y5yb6c+PimU/88wzmTW11Hk++KUAAIhoCgCAiKYAAIhoCgCAiKYAAIhoCgCAiKYAAIjynqdw1llnuXVvidySkhJ3rMquq6Vkq6qqMmteHj+f1/ay1Gq5ZJXx9pYlLiwsdMeqZbkVLzev3lsdU29pYLUkscpwq2PqnRNvLo2ZvxyymdnOnTvdukddZ//xH//h1r28/5e+9CV37NSpU926N09BneutW7e6de/zo5ZB37Vrl1tXy197mX11jav3rq2tzaxVVFS4Yzdu3OjW1Wfb+wytX7/eHZsPfikAACKaAgAgoikAACKaAgAgoikAACKaAgAgoikAAKK8w+5qfXFvLXovY22m8+PqfgvevR5UZljdE8HLxRcUFLhjvfs8mPkZbnXfALWOvXcfCDN/29RYby15M7OBAwdm1tR8F5Uf7+jocOveMVX3NFBzIDwqz79mzRq3/uabb7r122+/PbN2/fXXu2PVfQu863jPnj3uWDVXZ8yYMZm1l156yR07c+ZMtz5jxgy3Pnz48MyaurfGunXr3Lp3vmpqatyx6v4Xau6HN69L7Vc++KUAAIhoCgCAiKYAAIhoCgCAiKYAAIhoCgCAiKYAAIjynqeg5gp49zSorKx0xx44cMCtNzU1uXUv17tjxw53rJoj0dbWlllTcwXUHAmVufekbLcar7Lnas6KN9dA3bPAu8eEmT5m3nwBNZdA5flbW1szaypz//zzz7t1tYa+l7lX93koLS11697na9u2bb0ea2Y2adKkzNrYsWPdsYMGDXLr6j4Ro0aNyqx5c5vy4c15UXMFvHk8Zv4xM/OvY/Vdmg9+KQAAIpoCACCiKQAAIpoCACCiKQAAIpoCACDKO5KqeHE9Fc304qz51L3leRsbG92xW7Zsceve+CNHjrhjW1pa3Lq3fLUXQTTTkVQV7fQixmpJcLW0tjdexT5VNFNtm7fkuBqrzqcX93v55ZfdsW+99VavX9vMbOXKlZk19fk644wz3Lp3Laml5dUx9a5jFS9Wn10Vk/eiuGoZdbVt3nEZN26cO7ahoaHXr21mdt5552XWVNw1H/xSAABENAUAQERTAABENAUAQERTAABENAUAQERTAABEBUGtZQwA+JPBLwUAQERTAABENAUAQERTAABENAUAQERTAABENAUAQERTAABENAUAQPT/AJ85vTwHjOAPAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data loading and preprocessing cell executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape=(IMG_WIDTH, IMG_HEIGHT, 1), num_classes=NUM_CLASSES):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "# --- Callbacks Configuration ---\n",
        "# !!! IMPORTANT: ADJUST THIS PATH if you want to save the model elsewhere in your Drive !!!\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/fer2013_emotion_model_best.h5'\n",
        "callbacks_list = []\n",
        "validation_data_for_fit = None\n",
        "monitor_metric_checkpoint = 'loss' # Default if no validation data\n",
        "monitor_mode_checkpoint = 'min'\n",
        "monitor_metric_earlystop_lr = 'loss' # Default if no validation data\n",
        "\n",
        "if X_val.shape[0] > 0 and y_val.shape[0] > 0:\n",
        "    print(\"Validation data found. Callbacks will monitor validation metrics.\")\n",
        "    validation_data_for_fit = (X_val, y_val)\n",
        "    monitor_metric_checkpoint = 'val_accuracy'\n",
        "    monitor_mode_checkpoint = 'max'\n",
        "    monitor_metric_earlystop_lr = 'val_loss'\n",
        "else:\n",
        "    print(\"No validation data (X_val is empty). Callbacks will monitor training metrics.\")\n",
        "\n",
        "checkpoint = ModelCheckpoint(MODEL_SAVE_PATH,\n",
        "                             monitor=monitor_metric_checkpoint,\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode=monitor_mode_checkpoint)\n",
        "callbacks_list.append(checkpoint)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=monitor_metric_earlystop_lr,\n",
        "                               patience=10,\n",
        "                               verbose=1,\n",
        "                               restore_best_weights=True)\n",
        "callbacks_list.append(early_stopping)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor=monitor_metric_earlystop_lr,\n",
        "                              factor=0.2,\n",
        "                              patience=5,\n",
        "                              verbose=1,\n",
        "                              min_lr=0.00001)\n",
        "callbacks_list.append(reduce_lr)\n",
        "\n",
        "# --- Train the model ---\n",
        "if X_train.shape[0] > 0:\n",
        "    print(\"\\n--- Starting Model Training ---\")\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=EPOCHS,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        validation_data=validation_data_for_fit,\n",
        "                        callbacks=callbacks_list,\n",
        "                        verbose=1)\n",
        "\n",
        "    print(\"\\nTraining finished.\")\n",
        "    print(\"Available keys in history.history:\", history.history.keys())\n",
        "\n",
        "    # --- Plot training history ---\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    if 'accuracy' in history.history:\n",
        "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    if 'val_accuracy' in history.history:\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    elif validation_data_for_fit is None:\n",
        "        print(\"Plotting: No validation data was provided, so 'val_accuracy' is not plotted.\")\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    if 'accuracy' in history.history or 'val_accuracy' in history.history:\n",
        "        plt.legend(loc='lower right')\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    if 'loss' in history.history:\n",
        "        plt.plot(history.history['loss'], label='Train Loss')\n",
        "    if 'val_loss' in history.history:\n",
        "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    elif validation_data_for_fit is None:\n",
        "        print(\"Plotting: No validation data was provided, so 'val_loss' is not plotted.\")\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    if 'loss' in history.history or 'val_loss' in history.history:\n",
        "        plt.legend(loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"CRITICAL: X_train is empty. Skipping model training and evaluation.\")\n",
        "    history = None # Ensure history is defined even if training is skipped\n",
        "\n",
        "# --- Evaluate on test set (if test data and model training occurred) ---\n",
        "if history and X_test.shape[0] > 0:\n",
        "    print(\"\\n--- Evaluating on Test Set ---\")\n",
        "    # Load the best model saved by ModelCheckpoint for evaluation\n",
        "    try:\n",
        "        best_model = load_model(MODEL_SAVE_PATH)\n",
        "        print(f\"Successfully loaded best model from {MODEL_SAVE_PATH} for evaluation.\")\n",
        "        test_loss, test_accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f\"Test Loss: {test_loss:.4f}\")\n",
        "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load the best model from {MODEL_SAVE_PATH}. Error: {e}\")\n",
        "        print(\"Evaluating with the model state at the end of training (if EarlyStopping restored best weights).\")\n",
        "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(f\"Test Loss (current model state): {test_loss:.4f}\")\n",
        "        print(f\"Test Accuracy (current model state): {test_accuracy:.4f}\")\n",
        "\n",
        "elif not history:\n",
        "    print(\"\\nSkipping evaluation on test set because model training was skipped (X_train was empty).\")\n",
        "elif X_test.shape[0] == 0:\n",
        "    print(\"\\nSkipping evaluation on test set because X_test is empty.\")\n",
        "\n",
        "print(\"\\nModel building, training, and evaluation cell executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jdplJRth15lH",
        "outputId": "f388b310-73b9-4e63-d54d-714cbab0e243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m1,179,904\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m1,799\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,470,951\u001b[0m (5.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,470,951</span> (5.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,469,543\u001b[0m (5.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,469,543</span> (5.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation data found. Callbacks will monitor validation metrics.\n",
            "\n",
            "--- Starting Model Training ---\n",
            "Epoch 1/60\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2764 - loss: 2.2169\n",
            "Epoch 1: val_accuracy improved from -inf to 0.32154, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 38ms/step - accuracy: 0.2765 - loss: 2.2161 - val_accuracy: 0.3215 - val_loss: 1.8509 - learning_rate: 0.0010\n",
            "Epoch 2/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4529 - loss: 1.4416\n",
            "Epoch 2: val_accuracy improved from 0.32154 to 0.52132, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.4530 - loss: 1.4414 - val_accuracy: 0.5213 - val_loss: 1.2645 - learning_rate: 0.0010\n",
            "Epoch 3/60\n",
            "\u001b[1m447/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5259 - loss: 1.2521\n",
            "Epoch 3: val_accuracy improved from 0.52132 to 0.55085, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.5259 - loss: 1.2520 - val_accuracy: 0.5508 - val_loss: 1.2152 - learning_rate: 0.0010\n",
            "Epoch 4/60\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5543 - loss: 1.1717\n",
            "Epoch 4: val_accuracy improved from 0.55085 to 0.55754, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.5543 - loss: 1.1717 - val_accuracy: 0.5575 - val_loss: 1.1745 - learning_rate: 0.0010\n",
            "Epoch 5/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5807 - loss: 1.1068\n",
            "Epoch 5: val_accuracy did not improve from 0.55754\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.5807 - loss: 1.1069 - val_accuracy: 0.5350 - val_loss: 1.2316 - learning_rate: 0.0010\n",
            "Epoch 6/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5988 - loss: 1.0658\n",
            "Epoch 6: val_accuracy improved from 0.55754 to 0.58596, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.5988 - loss: 1.0658 - val_accuracy: 0.5860 - val_loss: 1.1538 - learning_rate: 0.0010\n",
            "Epoch 7/60\n",
            "\u001b[1m446/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6151 - loss: 1.0234\n",
            "Epoch 7: val_accuracy improved from 0.58596 to 0.59264, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.6151 - loss: 1.0235 - val_accuracy: 0.5926 - val_loss: 1.0958 - learning_rate: 0.0010\n",
            "Epoch 8/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6205 - loss: 1.0036\n",
            "Epoch 8: val_accuracy did not improve from 0.59264\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.6205 - loss: 1.0037 - val_accuracy: 0.5539 - val_loss: 1.2346 - learning_rate: 0.0010\n",
            "Epoch 9/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6367 - loss: 0.9646\n",
            "Epoch 9: val_accuracy improved from 0.59264 to 0.59738, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.6367 - loss: 0.9646 - val_accuracy: 0.5974 - val_loss: 1.1145 - learning_rate: 0.0010\n",
            "Epoch 10/60\n",
            "\u001b[1m446/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6594 - loss: 0.9178\n",
            "Epoch 10: val_accuracy did not improve from 0.59738\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.6593 - loss: 0.9180 - val_accuracy: 0.5160 - val_loss: 1.5732 - learning_rate: 0.0010\n",
            "Epoch 11/60\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6779 - loss: 0.8621\n",
            "Epoch 11: val_accuracy improved from 0.59738 to 0.60212, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.6779 - loss: 0.8621 - val_accuracy: 0.6021 - val_loss: 1.0616 - learning_rate: 0.0010\n",
            "Epoch 12/60\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6982 - loss: 0.8235\n",
            "Epoch 12: val_accuracy improved from 0.60212 to 0.61744, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.6981 - loss: 0.8235 - val_accuracy: 0.6174 - val_loss: 1.0459 - learning_rate: 0.0010\n",
            "Epoch 13/60\n",
            "\u001b[1m446/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7115 - loss: 0.7765\n",
            "Epoch 13: val_accuracy did not improve from 0.61744\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.7114 - loss: 0.7767 - val_accuracy: 0.5893 - val_loss: 1.1689 - learning_rate: 0.0010\n",
            "Epoch 14/60\n",
            "\u001b[1m447/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7117 - loss: 0.7760\n",
            "Epoch 14: val_accuracy improved from 0.61744 to 0.63082, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.7116 - loss: 0.7761 - val_accuracy: 0.6308 - val_loss: 1.0622 - learning_rate: 0.0010\n",
            "Epoch 15/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7364 - loss: 0.7205\n",
            "Epoch 15: val_accuracy did not improve from 0.63082\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7364 - loss: 0.7206 - val_accuracy: 0.6172 - val_loss: 1.0939 - learning_rate: 0.0010\n",
            "Epoch 16/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7521 - loss: 0.6756\n",
            "Epoch 16: val_accuracy did not improve from 0.63082\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.7521 - loss: 0.6757 - val_accuracy: 0.6308 - val_loss: 1.0813 - learning_rate: 0.0010\n",
            "Epoch 17/60\n",
            "\u001b[1m446/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7640 - loss: 0.6467\n",
            "Epoch 17: val_accuracy did not improve from 0.63082\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7639 - loss: 0.6469 - val_accuracy: 0.6269 - val_loss: 1.0686 - learning_rate: 0.0010\n",
            "Epoch 18/60\n",
            "\u001b[1m447/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7981 - loss: 0.5520\n",
            "Epoch 18: val_accuracy improved from 0.63082 to 0.65311, saving model to /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.7981 - loss: 0.5519 - val_accuracy: 0.6531 - val_loss: 1.0598 - learning_rate: 2.0000e-04\n",
            "Epoch 19/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8186 - loss: 0.5021\n",
            "Epoch 19: val_accuracy did not improve from 0.65311\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8186 - loss: 0.5020 - val_accuracy: 0.6495 - val_loss: 1.0966 - learning_rate: 2.0000e-04\n",
            "Epoch 20/60\n",
            "\u001b[1m448/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8298 - loss: 0.4639\n",
            "Epoch 20: val_accuracy did not improve from 0.65311\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.8298 - loss: 0.4639 - val_accuracy: 0.6517 - val_loss: 1.1173 - learning_rate: 2.0000e-04\n",
            "Epoch 21/60\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8385 - loss: 0.4353\n",
            "Epoch 21: val_accuracy did not improve from 0.65311\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8385 - loss: 0.4353 - val_accuracy: 0.6489 - val_loss: 1.1592 - learning_rate: 2.0000e-04\n",
            "Epoch 22/60\n",
            "\u001b[1m446/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8465 - loss: 0.4252\n",
            "Epoch 22: val_accuracy did not improve from 0.65311\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.8465 - loss: 0.4252 - val_accuracy: 0.6506 - val_loss: 1.1665 - learning_rate: 2.0000e-04\n",
            "Epoch 22: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\n",
            "Training finished.\n",
            "Available keys in history.history: dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss', 'learning_rate'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating on Test Set ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded best model from /content/drive/MyDrive/fer2013_emotion_model_best.h5 for evaluation.\n",
            "Test Loss: 1.0124\n",
            "Test Accuracy: 0.6556\n",
            "\n",
            "Model building, training, and evaluation cell executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Download Haar Cascade file for face detection ---\n",
        "HAAR_CASCADE_URL = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "HAAR_CASCADE_FILENAME = \"haarcascade_frontalface_default.xml\"\n",
        "MODEL_SAVE_PATH=\"/content/fer2013_emotion_model_best.h5\"\n",
        "# Using wget to download\n",
        "import os\n",
        "if not os.path.exists(HAAR_CASCADE_FILENAME):\n",
        "    print(f\"Downloading {HAAR_CASCADE_FILENAME}...\")\n",
        "    os.system(f\"wget {HAAR_CASCADE_URL} -O {HAAR_CASCADE_FILENAME}\")\n",
        "    if os.path.exists(HAAR_CASCADE_FILENAME):\n",
        "        print(\"Download complete.\")\n",
        "    else:\n",
        "        print(f\"ERROR: Failed to download {HAAR_CASCADE_FILENAME}.\")\n",
        "else:\n",
        "    print(f\"{HAAR_CASCADE_FILENAME} already exists.\")\n",
        "\n",
        "# --- Load Haar Cascade for face detection ---\n",
        "face_cascade = cv2.CascadeClassifier(HAAR_CASCADE_FILENAME)\n",
        "if face_cascade.empty():\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(f\"CRITICAL ERROR: Failed to load Haar Cascade from '{HAAR_CASCADE_FILENAME}'.\")\n",
        "    print(\"Face detection will not work. Ensure the file was downloaded correctly.\")\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "else:\n",
        "    print(\"Haar Cascade for face detection loaded successfully.\")\n",
        "\n",
        "# --- Load the Trained Emotion Model ---\n",
        "# Uses MODEL_SAVE_PATH defined in the previous cell\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "MODEL_TO_LOAD_PATH = '/content/fer2013_emotion_model_best.h5'\n",
        "\n",
        "emotion_model = None\n",
        "try:\n",
        "\n",
        "    emotion_model = load_model(MODEL_TO_LOAD_PATH)\n",
        "    print(f\"Emotion detection model loaded successfully from: {MODEL_TO_LOAD_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(f\"CRITICAL ERROR: Failed to load the trained emotion model from '{MODEL_TO_LOAD_PATH}'. Error: {e}\")\n",
        "    print(\"Real-time emotion prediction will not work correctly. Ensure the model was trained and saved.\")\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    emotion_model = None # Set to None to handle gracefully in the next cell\n",
        "\n",
        "print(\"\\nReal-time detection setup cell executed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaxIK0Cd3YRv",
        "outputId": "74f6da75-b4ce-4dc2-e4cb-3ec0a30b1fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "haarcascade_frontalface_default.xml already exists.\n",
            "Haar Cascade for face detection loaded successfully.\n",
            "Mounted at /content/drive\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "CRITICAL ERROR: Failed to load the trained emotion model from '/content/fer2013_emotion_model_best.h5'. Error: name 'load_model' is not defined\n",
            "Real-time emotion prediction will not work correctly. Ensure the model was trained and saved.\n",
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "\n",
            "Real-time detection setup cell executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW TEST CELL - Run this after restarting runtime\n",
        "\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Explicitly import load_model right here\n",
        "from tensorflow.keras.models import load_model\n",
        "print(f\"Type of load_model after import: {type(load_model)}\")\n",
        "\n",
        "# Ensure Google Drive is mounted if your model is there\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True) # force_remount can sometimes help\n",
        "    print(\"Google Drive mounted.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting drive: {e}\")\n",
        "\n",
        "MODEL_PATH_TO_TEST = '/content/fer2013_emotion_model_best.h5' #  <--- VERIFY THIS PATH IS CORRECT\n",
        "emotion_model_test = None\n",
        "\n",
        "print(f\"\\nAttempting to load model from: {MODEL_PATH_TO_TEST}\")\n",
        "try:\n",
        "    if 'load_model' in globals() and callable(load_model):\n",
        "        print(\"'load_model' IS in globals and is callable.\")\n",
        "        emotion_model_test = load_model(MODEL_PATH_TO_TEST)\n",
        "        if emotion_model_test is not None:\n",
        "            print(\"SUCCESS: Model loaded successfully in this isolated test!\")\n",
        "            emotion_model_test.summary()\n",
        "        else:\n",
        "            print(\"ERROR: load_model ran but returned None (model file might be corrupt or not a Keras model).\")\n",
        "    else:\n",
        "        print(\"CRITICAL ERROR: 'load_model' is NOT in globals or is not callable, even after import in this cell.\")\n",
        "        # Let's see what load_model is, if it exists\n",
        "        if 'load_model' in globals():\n",
        "            print(f\"Type of 'load_model' in globals is actually: {type(globals()['load_model'])}\")\n",
        "        else:\n",
        "            print(\"'load_model' is not in globals at all.\")\n",
        "        # Let's check tf.keras.models directly\n",
        "        if hasattr(tf.keras.models, 'load_model'):\n",
        "            print(\"tf.keras.models HAS an attribute 'load_model'.\")\n",
        "            print(f\"Type of tf.keras.models.load_model is: {type(tf.keras.models.load_model)}\")\n",
        "        else:\n",
        "            print(\"tf.keras.models does NOT have an attribute 'load_model'. This is very strange.\")\n",
        "\n",
        "\n",
        "except NameError as ne:\n",
        "    print(f\"NameError during load_model call: {ne}\")\n",
        "    print(\"This means 'load_model' was still not defined when called.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"FileNotFoundError: Model file not found at '{MODEL_PATH_TO_TEST}'.\")\n",
        "    print(\"Please verify the path and ensure the file exists in your Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred while trying to load the model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "icjya5ny0ccr",
        "outputId": "68813b7c-8eca-4ab5-978a-d0af3e749b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Type of load_model after import: <class 'function'>\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted.\n",
            "\n",
            "Attempting to load model from: /content/fer2013_emotion_model_best.h5\n",
            "'load_model' IS in globals and is callable.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: Model loaded successfully in this isolated test!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,470,953\u001b[0m (5.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,470,953</span> (5.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,469,543\u001b[0m (5.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,469,543</span> (5.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Real-time Detection Setup (REPLACED WITH WORKING CODE)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(f\"TensorFlow version (Cell 4): {tf.__version__}\")\n",
        "\n",
        "# Explicitly import load_model right here\n",
        "from tensorflow.keras.models import load_model\n",
        "print(f\"Type of load_model after import (Cell 4): {type(load_model)}\")\n",
        "\n",
        "import os\n",
        "import cv2 # For Haar Cascade\n",
        "\n",
        "# Ensure Google Drive is mounted if your model is there\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False) # force_remount=True if you suspect issues\n",
        "    print(\"Google Drive mounted (Cell 4).\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting drive (Cell 4): {e}\")\n",
        "\n",
        "# --- Download Haar Cascade file for face detection ---\n",
        "HAAR_CASCADE_URL = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "HAAR_CASCADE_FILENAME = \"haarcascade_frontalface_default.xml\"\n",
        "\n",
        "if not os.path.exists(HAAR_CASCADE_FILENAME):\n",
        "    print(f\"Downloading {HAAR_CASCADE_FILENAME}...\")\n",
        "    os.system(f\"wget {HAAR_CASCADE_URL} -O {HAAR_CASCADE_FILENAME}\")\n",
        "    if os.path.exists(HAAR_CASCADE_FILENAME): print(\"Download complete.\")\n",
        "    else: print(f\"ERROR: Failed to download {HAAR_CASCADE_FILENAME}.\")\n",
        "else:\n",
        "    print(f\"{HAAR_CASCADE_FILENAME} already exists.\")\n",
        "\n",
        "# --- Load Haar Cascade for face detection ---\n",
        "face_cascade = cv2.CascadeClassifier(HAAR_CASCADE_FILENAME)\n",
        "if face_cascade.empty():\n",
        "    print(\"CRITICAL ERROR: Failed to load Haar Cascade.\")\n",
        "else:\n",
        "    print(\"Haar Cascade for face detection loaded successfully.\")\n",
        "\n",
        "# --- Load the Trained Emotion Model ---\n",
        "MODEL_LOAD_PATH = '/content/fer2013_emotion_model_best.h5' # Make sure this is your correct model path\n",
        "emotion_model = None # Initialize to ensure it's defined\n",
        "\n",
        "print(f\"\\nAttempting to load emotion model from: {MODEL_LOAD_PATH}\")\n",
        "try:\n",
        "    if callable(load_model): # Check if load_model is a callable function\n",
        "        emotion_model = load_model(MODEL_LOAD_PATH) # Assign to the global 'emotion_model'\n",
        "        if emotion_model is not None:\n",
        "            print(\"SUCCESS: Emotion model loaded successfully!\")\n",
        "            # emotion_model.summary() # Optional: display summary\n",
        "        else:\n",
        "            print(\"ERROR: load_model ran but returned None.\")\n",
        "    else:\n",
        "        print(\"CRITICAL ERROR: 'load_model' is not callable in this cell's scope.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"FileNotFoundError: Model file not found at '{MODEL_LOAD_PATH}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred while loading the model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# Ensure emotion_model is not None before proceeding to Cell 5\n",
        "if emotion_model is None:\n",
        "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(\"CRITICAL ERROR: emotion_model was NOT loaded. Real-time detection will fail.\")\n",
        "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "\n",
        "\n",
        "print(\"\\nReal-time detection setup cell (Cell 4) executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPbNeS9M1YFT",
        "outputId": "215a0b80-11b6-43c2-d591-cf3a92857e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version (Cell 4): 2.18.0\n",
            "Type of load_model after import (Cell 4): <class 'function'>\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted (Cell 4).\n",
            "haarcascade_frontalface_default.xml already exists.\n",
            "Haar Cascade for face detection loaded successfully.\n",
            "\n",
            "Attempting to load emotion model from: /content/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: Emotion model loaded successfully!\n",
            "\n",
            "Real-time detection setup cell (Cell 4) executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1: PYTHON BACKEND FOR INTERACTIVE DETECTION\n",
        "\n",
        "from google.colab.output import register_callback, eval_js\n",
        "from IPython.display import display, Javascript # Javascript is for the UI cell in Cell 2\n",
        "import numpy as np\n",
        "import cv2\n",
        "from base64 import b64decode, b64encode\n",
        "import traceback # For detailed error printing\n",
        "\n",
        "# --- Ensure these are loaded from your previous cells ---\n",
        "# For example:\n",
        "# IMG_WIDTH, IMG_HEIGHT = 48, 48\n",
        "# EMOTION_LABELS = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "# face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # Make sure this file exists\n",
        "# emotion_model = load_model('/content/drive/MyDrive/fer2013_emotion_model_best.h5') # Adjust path as needed\n",
        "\n",
        "# --- Helper function for drawing (should be defined from previous steps) ---\n",
        "def draw_prediction(frame, x, y, w, h, label_text, color=(0, 255, 0)):\n",
        "    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "    cv2.putText(frame, label_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "    return frame\n",
        "# --- End Ensure/Define ---\n",
        "\n",
        "\n",
        "def detect_emotion_on_captured_frame(base64_image_data_url):\n",
        "    \"\"\"\n",
        "    Processes a single base64 encoded image, performs emotion detection,\n",
        "    and sends the processed image back to JavaScript.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"Python: Received image data for processing from JS.\")\n",
        "\n",
        "        header, base64_data = base64_image_data_url.split(',', 1)\n",
        "        image_bytes = b64decode(base64_data)\n",
        "        frame = cv2.imdecode(np.frombuffer(image_bytes, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "        if frame is None:\n",
        "            print(\"Python: Frame decoding failed.\")\n",
        "            eval_js('window.colabApp.displayError(\"Python: Failed to decode image.\")')\n",
        "            return\n",
        "\n",
        "        print(f\"Python: Frame decoded successfully, shape: {frame.shape}\")\n",
        "\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n",
        "\n",
        "        detection_message = \"No faces detected.\"\n",
        "        # Default to original frame if no face or error in processing\n",
        "        _, buffer = cv2.imencode('.jpg', frame) # Encode original frame initially\n",
        "        processed_img_b64 = 'data:image/jpeg;base64,' + b64encode(buffer).decode()\n",
        "\n",
        "        # --- CORRECTED CHECK FOR FACES ---\n",
        "        # Using len(faces) > 0 is robust as detectMultiScale returns empty tuple () if no faces.\n",
        "        if len(faces) > 0:\n",
        "            print(f\"Python: Detected {len(faces)} face(s). Processing the first one.\")\n",
        "            x, y, w, h = faces[0] # Process the first detected face\n",
        "            face_roi_gray = gray_frame[y:y+h, x:x+w]\n",
        "\n",
        "            if face_roi_gray.size > 0:\n",
        "                resized_face = cv2.resize(face_roi_gray, (IMG_WIDTH, IMG_HEIGHT))\n",
        "                normalized_face = resized_face / 255.0\n",
        "                reshaped_face = normalized_face.reshape(1, IMG_WIDTH, IMG_HEIGHT, 1)\n",
        "\n",
        "                prediction = emotion_model.predict(reshaped_face, verbose=0)\n",
        "                emotion_index = np.argmax(prediction)\n",
        "                emotion_label_str = EMOTION_LABELS[emotion_index]\n",
        "                confidence = np.max(prediction)\n",
        "                detection_message = f\"Detected: {emotion_label_str} ({confidence*100:.1f}%)\"\n",
        "\n",
        "                frame_annotated = draw_prediction(frame.copy(), x, y, w, h, detection_message)\n",
        "\n",
        "                _, buffer = cv2.imencode('.jpg', frame_annotated)\n",
        "                processed_img_b64 = 'data:image/jpeg;base64,' + b64encode(buffer).decode()\n",
        "                print(f\"Python: {detection_message}\")\n",
        "            else:\n",
        "                detection_message = \"Face ROI was empty (unexpected).\"\n",
        "                print(f\"Python: {detection_message}\")\n",
        "                # processed_img_b64 remains the original frame's encoding\n",
        "        else: # No faces detected\n",
        "            print(\"Python: No faces detected in the captured frame.\")\n",
        "            # detection_message is already \"No faces detected.\"\n",
        "            # processed_img_b64 is already the original frame's encoding\n",
        "\n",
        "        # Send the processed image and message back to JavaScript\n",
        "        eval_js(f'window.colabApp.updateResult(\"{processed_img_b64}\", \"{detection_message}\");')\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"Python Error processing frame: {str(e)}\"\n",
        "        print(error_message)\n",
        "        traceback.print_exc()\n",
        "\n",
        "        # Prepare the error message for safe embedding in JavaScript\n",
        "        js_safe_error_message = error_message.replace('\\\\', '\\\\\\\\') \\\n",
        "                                             .replace('\"', '\\\\\"') \\\n",
        "                                             .replace('\\n', '\\\\n') \\\n",
        "                                             .replace('\\r', '\\\\r')\n",
        "        try:\n",
        "            eval_js(f'window.colabApp.displayError(\"{js_safe_error_message}\");')\n",
        "        except Exception as eval_e:\n",
        "            print(f\"Python: Failed to send error to JS via eval_js: {eval_e}\")\n",
        "\n",
        "\n",
        "# Register the Python function so JavaScript can call it\n",
        "try:\n",
        "    register_callback('colab_detect_emotion_callback', detect_emotion_on_captured_frame)\n",
        "    print(\"Python: Callback 'colab_detect_emotion_callback' registered successfully.\")\n",
        "    print(\"Python: Ready for JavaScript UI cell to be executed.\")\n",
        "except Exception as e:\n",
        "    print(f\"Python: Error registering callback: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCRAdLjxJmca",
        "outputId": "779e7121-ae9b-447e-a261-f4649a0191f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: Callback 'colab_detect_emotion_callback' registered successfully.\n",
            "Python: Ready for JavaScript UI cell to be executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: JAVASCRIPT UI FOR INTERACTIVE DETECTION\n",
        "\n",
        "js_ui_code = Javascript('''\n",
        "(function() { // IIFE to avoid polluting global scope and allow re-runs\n",
        "    console.log(\"JS: Initializing Interactive Emotion Detection UI...\");\n",
        "\n",
        "    // Cleanup previous UI if it exists (for re-running the cell)\n",
        "    const existingAppContainer = document.getElementById('interactiveEmotionAppContainer');\n",
        "    if (existingAppContainer) {\n",
        "        console.log(\"JS: Cleaning up existing UI elements...\");\n",
        "        if (window.colabApp && window.colabApp.stopCameraAndCleanup) {\n",
        "            window.colabApp.stopCameraAndCleanup(); // Call previous stop function if available\n",
        "        }\n",
        "        existingAppContainer.remove();\n",
        "    }\n",
        "\n",
        "    const appContainer = document.createElement('div');\n",
        "    appContainer.id = 'interactiveEmotionAppContainer';\n",
        "    document.body.appendChild(appContainer);\n",
        "\n",
        "    appContainer.innerHTML = `\n",
        "        <style>\n",
        "            #interactiveEmotionAppContainer { padding: 10px; font-family: Arial, sans-serif; display: flex; flex-direction: column; align-items: center; max-width: 640px; margin: auto;}\n",
        "            #interactiveEmotionAppContainer video#liveVideoFeed { border: 2px solid #333; margin-bottom: 10px; background-color: #f0f0f0; width:100%; max-width:600px; height:auto;}\n",
        "            #interactiveEmotionAppContainer img#detectionResultDisplay { border: 2px solid #4CAF50; margin-top: 10px; min-height: 240px; background-color: #e8e8e8; object-fit: contain; width:100%; max-width:600px; height:auto;}\n",
        "            #interactiveEmotionAppContainer .controls button { margin: 5px; padding: 10px 15px; font-size: 16px; cursor: pointer; border-radius: 5px; border: none; color: white; }\n",
        "            #interactiveEmotionAppContainer #captureAndDetectBtn { background-color: #007bff; }\n",
        "            #interactiveEmotionAppContainer #stopWebcamBtn { background-color: #dc3545; }\n",
        "            #interactiveEmotionAppContainer #uiStatusMessage { margin-top: 10px; font-style: italic; color: #555; min-height: 20px; text-align: center;}\n",
        "        </style>\n",
        "        <h3>Interactive Emotion Detection</h3>\n",
        "        <video id=\"liveVideoFeed\" playsinline autoplay muted></video>\n",
        "        <div class=\"controls\">\n",
        "            <button id=\"captureAndDetectBtn\" disabled>Capture & Detect</button>\n",
        "            <button id=\"stopWebcamBtn\" disabled>Stop Camera</button>\n",
        "        </div>\n",
        "        <div id=\"uiStatusMessage\">Status: Initializing...</div>\n",
        "        <img id=\"detectionResultDisplay\" alt=\"Detection Result\"/>\n",
        "    `;\n",
        "\n",
        "    const videoElement = document.getElementById('liveVideoFeed');\n",
        "    const captureButton = document.getElementById('captureAndDetectBtn');\n",
        "    const stopButton = document.getElementById('stopWebcamBtn');\n",
        "    const statusDiv = document.getElementById('uiStatusMessage');\n",
        "    const resultImageElement = document.getElementById('detectionResultDisplay');\n",
        "    let currentStream = null;\n",
        "    let hiddenCanvasForCapture = null;\n",
        "\n",
        "    async function startCamera() {\n",
        "        statusDiv.textContent = 'Status: Starting camera...';\n",
        "        captureButton.disabled = true;\n",
        "        stopButton.disabled = true;\n",
        "        resultImageElement.src = ''; // Clear previous image\n",
        "\n",
        "        try {\n",
        "            if (currentStream) { // Stop any existing stream\n",
        "                currentStream.getTracks().forEach(track => track.stop());\n",
        "            }\n",
        "            // Request a common resolution, browser will try its best\n",
        "            const constraints = { video: { width: { ideal: 640 }, height: { ideal: 480 } } };\n",
        "            currentStream = await navigator.mediaDevices.getUserMedia(constraints);\n",
        "            videoElement.srcObject = currentStream;\n",
        "            videoElement.onloadedmetadata = () => {\n",
        "                if (!videoElement) return; // Element might have been removed\n",
        "                hiddenCanvasForCapture = document.createElement('canvas');\n",
        "                hiddenCanvasForCapture.width = videoElement.videoWidth;\n",
        "                hiddenCanvasForCapture.height = videoElement.videoHeight;\n",
        "                statusDiv.textContent = 'Status: Camera ON. Click \"Capture & Detect\".';\n",
        "                captureButton.disabled = false;\n",
        "                stopButton.disabled = false;\n",
        "                console.log(\"JS: Camera started. Hidden canvas ready for captures.\");\n",
        "            };\n",
        "            videoElement.onerror = (e) => {\n",
        "                console.error(\"JS Video Error:\", e);\n",
        "                statusDiv.textContent = 'Status: Video element error. ' + (e.message || '');\n",
        "            };\n",
        "        } catch (err) {\n",
        "            console.error(\"JS Error accessing camera: \", err);\n",
        "            statusDiv.textContent = 'Status: ERROR - Could not access camera. ' + err.message;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    function stopCameraAndCleanupInternal() {\n",
        "        console.log(\"JS: stopCameraAndCleanupInternal called.\");\n",
        "        if (currentStream) {\n",
        "            currentStream.getTracks().forEach(track => track.stop());\n",
        "            currentStream = null;\n",
        "        }\n",
        "        if(videoElement) videoElement.srcObject = null; // Clear video feed\n",
        "        statusDiv.textContent = 'Status: Camera OFF.';\n",
        "        captureButton.disabled = true;\n",
        "        // stopButton.disabled = true; // Optional: disable stop button too\n",
        "        console.log(\"JS: Camera and stream stopped and cleaned up.\");\n",
        "    }\n",
        "\n",
        "    captureButton.onclick = () => {\n",
        "        if (!currentStream || !hiddenCanvasForCapture || videoElement.paused || videoElement.ended || videoElement.readyState < videoElement.HAVE_ENOUGH_DATA) {\n",
        "            statusDiv.textContent = 'Status: Camera not ready or stream ended. Please ensure camera is active.';\n",
        "            console.warn(\"JS: Capture attempted but video not ready.\");\n",
        "            if(!currentStream) startCamera(); // Try to restart camera if stream is lost\n",
        "            return;\n",
        "        }\n",
        "        statusDiv.textContent = 'Status: Capturing frame...';\n",
        "        resultImageElement.src = '';\n",
        "\n",
        "        try {\n",
        "            hiddenCanvasForCapture.getContext('2d').drawImage(videoElement, 0, 0, videoElement.videoWidth, videoElement.videoHeight);\n",
        "            const imageDataUrl = hiddenCanvasForCapture.toDataURL('image/jpeg', 0.9); // Use JPEG for smaller size\n",
        "\n",
        "            statusDiv.textContent = 'Status: Sending frame to Python for detection...';\n",
        "            console.log(\"JS: Calling Python 'colab_detect_emotion_callback'.\");\n",
        "\n",
        "            google.colab.kernel.invokeFunction(\n",
        "                'colab_detect_emotion_callback',\n",
        "                [imageDataUrl],\n",
        "                {}\n",
        "            ).then(response => {\n",
        "                console.log(\"JS: Python function 'colab_detect_emotion_callback' acknowledged.\");\n",
        "            }).catch(err => {\n",
        "                console.error(\"JS Error calling Python function: \", err);\n",
        "                statusDiv.textContent = 'Status: ERROR communicating with Python: ' + err.message;\n",
        "            });\n",
        "        } catch (err) {\n",
        "            console.error(\"JS Error during frame capture/URL creation: \", err);\n",
        "            statusDiv.textContent = 'Status: ERROR during capture: ' + err.message;\n",
        "        }\n",
        "    };\n",
        "\n",
        "    stopButton.onclick = stopCameraAndCleanupInternal;\n",
        "\n",
        "    // Expose methods for Python to call\n",
        "    window.colabApp = {\n",
        "        updateResult: (imageDataB64, message) => {\n",
        "            console.log(\"JS: updateResult called by Python. Message: \" + message);\n",
        "            if(resultImageElement) resultImageElement.src = imageDataB64;\n",
        "            if(statusDiv) statusDiv.textContent = \"Status: \" + message;\n",
        "        },\n",
        "        displayError: (errorMessage) => {\n",
        "            console.error(\"JS: displayError called by Python: \" + errorMessage);\n",
        "            if(statusDiv) statusDiv.textContent = \"Status: PYTHON ERROR - \" + errorMessage;\n",
        "        },\n",
        "        stopCameraAndCleanup: stopCameraAndCleanupInternal // Allow Python to request a stop if needed\n",
        "    };\n",
        "\n",
        "    // Automatically start the camera when the UI is loaded\n",
        "    startCamera();\n",
        "\n",
        "})(); // End of IIFE\n",
        "''')\n",
        "display(js_ui_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "7-yQ2zoLJouO",
        "outputId": "bb6c6980-c96b-4d91-b044-3b4a769c3f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Javascript' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5208d979f7cf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CELL 2: JAVASCRIPT UI FOR INTERACTIVE DETECTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m js_ui_code = Javascript('''\n\u001b[0m\u001b[1;32m      4\u001b[0m (function() { // IIFE to avoid polluting global scope and allow re-runs\n\u001b[1;32m      5\u001b[0m     \u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JS: Initializing Interactive Emotion Detection UI...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Javascript' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1: SETUP AND IMPORTS\n",
        "\n",
        "import numpy as np\n",
        "# pandas might not be needed if not loading FER2013 for training\n",
        "# import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model # Crucial for loading the model\n",
        "# Other Keras layers might not be needed if you're not rebuilding the model architecture here\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# Callbacks are not needed if not training\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt # For any potential plotting (though less likely now)\n",
        "import cv2 # OpenCV for image processing and Haar Cascade\n",
        "from google.colab import drive # For Google Drive access\n",
        "# from google.colab import files # Less likely needed now\n",
        "from google.colab.patches import cv2_imshow # For displaying OpenCV images in Colab (if debugging)\n",
        "from IPython.display import display, Javascript # For webcam interaction (UI Cell)\n",
        "from base64 import b64decode, b64encode # For webcam data encoding/decoding\n",
        "from google.colab.output import eval_js, register_callback # For JS-Python communication\n",
        "\n",
        "# --- Configuration (Needed for model input and labels) ---\n",
        "IMG_WIDTH, IMG_HEIGHT = 48, 48\n",
        "NUM_CLASSES = 7 # Ensure this matches your pre-trained model's output\n",
        "EMOTION_LABELS = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "# BATCH_SIZE and EPOCHS are not needed if not training\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "print(\"OpenCV Version:\", cv2.__version__)\n",
        "print(\"Setup cell executed. Ready to load pre-trained model and run detection.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suOYjBQt4EGZ",
        "outputId": "cb308f67-e8da-44f2-8e7f-c9449879e61a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.18.0\n",
            "OpenCV Version: 4.11.0\n",
            "Setup cell executed. Ready to load pre-trained model and run detection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: LOAD PRE-TRAINED MODEL AND HAAR CASCADE\n",
        "\n",
        "# --- Mount Google Drive (if your model is there) ---\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False) # Set force_remount=True if you have issues\n",
        "    print(\"Google Drive mounted.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    # Depending on where your model is, this might be a critical error.\n",
        "\n",
        "# --- Define Path to your Pre-trained Model ---\n",
        "# !!! IMPORTANT: ADJUST THIS PATH to where your .h5 file is located !!!\n",
        "PRE_TRAINED_MODEL_PATH = '/content/drive/MyDrive/fer2013_emotion_model_best.h5'\n",
        "\n",
        "# --- Load the Pre-trained Emotion Model ---\n",
        "emotion_model = None # Initialize\n",
        "print(f\"\\nAttempting to load pre-trained emotion model from: {PRE_TRAINED_MODEL_PATH}\")\n",
        "try:\n",
        "    emotion_model = load_model(PRE_TRAINED_MODEL_PATH)\n",
        "    if emotion_model is not None:\n",
        "        print(\"SUCCESS: Pre-trained emotion model loaded successfully!\")\n",
        "        emotion_model.summary() # Display model architecture\n",
        "    else:\n",
        "        # This case should ideally not happen if load_model doesn't raise an error\n",
        "        print(\"ERROR: load_model ran but returned None. Model file might be corrupt or not a Keras model.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(f\"CRITICAL FILE NOT FOUND ERROR: Model file not found at '{PRE_TRAINED_MODEL_PATH}'.\")\n",
        "    print(\"Please ensure the path is correct and the model file exists in your Google Drive.\")\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "except Exception as e:\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(f\"CRITICAL ERROR loading pre-trained model: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "\n",
        "\n",
        "# --- Download and Load Haar Cascade for face detection ---\n",
        "import os\n",
        "HAAR_CASCADE_URL = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
        "HAAR_CASCADE_FILENAME = \"haarcascade_frontalface_default.xml\"\n",
        "\n",
        "if not os.path.exists(HAAR_CASCADE_FILENAME):\n",
        "    print(f\"\\nDownloading {HAAR_CASCADE_FILENAME}...\")\n",
        "    os.system(f\"wget {HAAR_CASCADE_URL} -O {HAAR_CASCADE_FILENAME}\")\n",
        "    if os.path.exists(HAAR_CASCADE_FILENAME): print(\"Download complete.\")\n",
        "    else: print(f\"ERROR: Failed to download {HAAR_CASCADE_FILENAME}.\")\n",
        "else:\n",
        "    print(f\"\\n{HAAR_CASCADE_FILENAME} already exists.\")\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(HAAR_CASCADE_FILENAME)\n",
        "if face_cascade.empty():\n",
        "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(f\"CRITICAL ERROR: Failed to load Haar Cascade from '{HAAR_CASCADE_FILENAME}'. Face detection will not work.\")\n",
        "    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "else:\n",
        "    print(\"Haar Cascade for face detection loaded successfully.\")\n",
        "\n",
        "# --- Final Check ---\n",
        "if emotion_model is None or face_cascade.empty():\n",
        "    print(\"\\nWARNING: Either the emotion model or the face cascade failed to load. Interactive detection may not work.\")\n",
        "else:\n",
        "    print(\"\\nPre-trained model and Haar cascade are ready for detection.\")\n",
        "\n",
        "print(\"\\nModel and Haar Cascade loading cell executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T22ThrrJ4GFh",
        "outputId": "66aad5a9-1638-4979-cad3-ecf7a4c77e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted.\n",
            "\n",
            "Attempting to load pre-trained emotion model from: /content/drive/MyDrive/fer2013_emotion_model_best.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: Pre-trained emotion model loaded successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,470,953\u001b[0m (5.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,470,953</span> (5.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,469,543\u001b[0m (5.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,469,543</span> (5.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "haarcascade_frontalface_default.xml already exists.\n",
            "Haar Cascade for face detection loaded successfully.\n",
            "\n",
            "Pre-trained model and Haar cascade are ready for detection.\n",
            "\n",
            "Model and Haar Cascade loading cell executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: PYTHON BACKEND FOR INTERACTIVE DETECTION (CALLBACK)\n",
        "\n",
        "# --- Helper function for drawing (should be defined from previous steps or here) ---\n",
        "def draw_prediction(frame, x, y, w, h, label_text, color=(0, 255, 0)):\n",
        "    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "    cv2.putText(frame, label_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "    return frame\n",
        "# --- End Helper ---\n",
        "\n",
        "def detect_emotion_on_captured_frame(base64_image_data_url):\n",
        "    \"\"\"\n",
        "    Processes a single base64 encoded image, performs emotion detection,\n",
        "    and sends the processed image back to JavaScript.\n",
        "    \"\"\"\n",
        "    global emotion_model, face_cascade # Ensure we're using the globally loaded ones\n",
        "\n",
        "    if emotion_model is None or face_cascade.empty():\n",
        "        error_message = \"Python Error: Model or face cascade not loaded.\"\n",
        "        print(error_message)\n",
        "        js_safe_error_message = error_message.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"').replace('\\n', '\\\\n').replace('\\r', '\\\\r')\n",
        "        try: eval_js(f'window.colabApp.displayError(\"{js_safe_error_message}\");')\n",
        "        except Exception as eval_e: print(f\"Python: Failed to send critical load error to JS: {eval_e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        print(\"Python: Received image data for processing from JS.\")\n",
        "\n",
        "        header, base64_data = base64_image_data_url.split(',', 1)\n",
        "        image_bytes = b64decode(base64_data)\n",
        "        frame = cv2.imdecode(np.frombuffer(image_bytes, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
        "\n",
        "        if frame is None:\n",
        "            print(\"Python: Frame decoding failed.\")\n",
        "            eval_js('window.colabApp.displayError(\"Python: Failed to decode image.\")')\n",
        "            return\n",
        "\n",
        "        # print(f\"Python: Frame decoded successfully, shape: {frame.shape}\") # Can be noisy\n",
        "\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        # Use the globally loaded face_cascade\n",
        "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n",
        "\n",
        "        detection_message = \"No faces detected.\"\n",
        "        _, buffer = cv2.imencode('.jpg', frame) # Encode original frame initially\n",
        "        processed_img_b64 = 'data:image/jpeg;base64,' + b64encode(buffer).decode()\n",
        "\n",
        "        if len(faces) > 0:\n",
        "            # print(f\"Python: Detected {len(faces)} face(s). Processing the first one.\") # Can be noisy\n",
        "            x, y, w, h = faces[0]\n",
        "            face_roi_gray = gray_frame[y:y+h, x:x+w]\n",
        "\n",
        "            if face_roi_gray.size > 0:\n",
        "                resized_face = cv2.resize(face_roi_gray, (IMG_WIDTH, IMG_HEIGHT))\n",
        "                normalized_face = resized_face / 255.0\n",
        "                reshaped_face = normalized_face.reshape(1, IMG_WIDTH, IMG_HEIGHT, 1)\n",
        "\n",
        "                # Use the globally loaded emotion_model\n",
        "                prediction = emotion_model.predict(reshaped_face, verbose=0)\n",
        "                emotion_index = np.argmax(prediction)\n",
        "                emotion_label_str = EMOTION_LABELS[emotion_index]\n",
        "                confidence = np.max(prediction)\n",
        "                detection_message = f\"Detected: {emotion_label_str} ({confidence*100:.1f}%)\"\n",
        "\n",
        "                frame_annotated = draw_prediction(frame.copy(), x, y, w, h, detection_message)\n",
        "\n",
        "                _, buffer = cv2.imencode('.jpg', frame_annotated)\n",
        "                processed_img_b64 = 'data:image/jpeg;base64,' + b64encode(buffer).decode()\n",
        "                # print(f\"Python: {detection_message}\") # Can be noisy\n",
        "            else:\n",
        "                detection_message = \"Face ROI was empty (unexpected).\"\n",
        "                # print(f\"Python: {detection_message}\")\n",
        "        # else: # No faces detected\n",
        "            # print(\"Python: No faces detected in the captured frame.\") # Can be noisy\n",
        "\n",
        "        eval_js(f'window.colabApp.updateResult(\"{processed_img_b64}\", \"{detection_message}\");')\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"Python Error processing frame: {str(e)}\"\n",
        "        print(error_message)\n",
        "        traceback.print_exc()\n",
        "        js_safe_error_message = error_message.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"').replace('\\n', '\\\\n').replace('\\r', '\\\\r')\n",
        "        try: eval_js(f'window.colabApp.displayError(\"{js_safe_error_message}\");')\n",
        "        except Exception as eval_e: print(f\"Python: Failed to send processing error to JS: {eval_e}\")\n",
        "\n",
        "# Register the Python function\n",
        "try:\n",
        "    register_callback('colab_detect_emotion_callback', detect_emotion_on_captured_frame)\n",
        "    print(\"Python: Callback 'colab_detect_emotion_callback' registered successfully.\")\n",
        "    print(\"Python: Ready for JavaScript UI cell to be executed.\")\n",
        "except Exception as e:\n",
        "    print(f\"Python: Error registering callback: {e}\")\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNjHSkpa4QUH",
        "outputId": "9e4a5dc4-f860-4d87-bee2-bf2fe054aef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: Callback 'colab_detect_emotion_callback' registered successfully.\n",
            "Python: Ready for JavaScript UI cell to be executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: JAVASCRIPT UI FOR INTERACTIVE DETECTION\n",
        "\n",
        "js_ui_code = Javascript('''\n",
        "(function() { // IIFE to avoid polluting global scope and allow re-runs\n",
        "    console.log(\"JS: Initializing Interactive Emotion Detection UI...\");\n",
        "\n",
        "    // Cleanup previous UI if it exists (for re-running the cell)\n",
        "    const existingAppContainer = document.getElementById('interactiveEmotionAppContainer');\n",
        "    if (existingAppContainer) {\n",
        "        console.log(\"JS: Cleaning up existing UI elements...\");\n",
        "        if (window.colabApp && window.colabApp.stopCameraAndCleanup) {\n",
        "            window.colabApp.stopCameraAndCleanup();\n",
        "        }\n",
        "        existingAppContainer.remove();\n",
        "    }\n",
        "\n",
        "    const appContainer = document.createElement('div');\n",
        "    appContainer.id = 'interactiveEmotionAppContainer';\n",
        "    document.body.appendChild(appContainer);\n",
        "\n",
        "    appContainer.innerHTML = `\n",
        "        <style>\n",
        "            #interactiveEmotionAppContainer { padding: 10px; font-family: Arial, sans-serif; display: flex; flex-direction: column; align-items: center; max-width: 640px; margin: auto;}\n",
        "            #interactiveEmotionAppContainer video#liveVideoFeed { border: 2px solid #333; margin-bottom: 10px; background-color: #f0f0f0; width:100%; max-width:600px; height:auto;}\n",
        "            #interactiveEmotionAppContainer img#detectionResultDisplay { border: 2px solid #4CAF50; margin-top: 10px; min-height: 240px; background-color: #e8e8e8; object-fit: contain; width:100%; max-width:600px; height:auto;}\n",
        "            #interactiveEmotionAppContainer .controls button { margin: 5px; padding: 10px 15px; font-size: 16px; cursor: pointer; border-radius: 5px; border: none; color: white; }\n",
        "            #interactiveEmotionAppContainer #captureAndDetectBtn { background-color: #007bff; }\n",
        "            #interactiveEmotionAppContainer #stopWebcamBtn { background-color: #dc3545; }\n",
        "            #interactiveEmotionAppContainer #uiStatusMessage { margin-top: 10px; font-style: italic; color: #555; min-height: 20px; text-align: center;}\n",
        "        </style>\n",
        "        <h3>Interactive Emotion Detection</h3>\n",
        "        <video id=\"liveVideoFeed\" playsinline autoplay muted></video>\n",
        "        <div class=\"controls\">\n",
        "            <button id=\"captureAndDetectBtn\" disabled>Capture & Detect</button>\n",
        "            <button id=\"stopWebcamBtn\" disabled>Stop Camera</button>\n",
        "        </div>\n",
        "        <div id=\"uiStatusMessage\">Status: Initializing...</div>\n",
        "        <img id=\"detectionResultDisplay\" alt=\"Detection Result\"/>\n",
        "    `;\n",
        "\n",
        "    const videoElement = document.getElementById('liveVideoFeed');\n",
        "    const captureButton = document.getElementById('captureAndDetectBtn');\n",
        "    const stopButton = document.getElementById('stopWebcamBtn');\n",
        "    const statusDiv = document.getElementById('uiStatusMessage');\n",
        "    const resultImageElement = document.getElementById('detectionResultDisplay');\n",
        "    let currentStream = null;\n",
        "    let hiddenCanvasForCapture = null;\n",
        "\n",
        "    async function startCamera() {\n",
        "        statusDiv.textContent = 'Status: Starting camera...';\n",
        "        captureButton.disabled = true;\n",
        "        stopButton.disabled = true;\n",
        "        resultImageElement.src = '';\n",
        "\n",
        "        try {\n",
        "            if (currentStream) {\n",
        "                currentStream.getTracks().forEach(track => track.stop());\n",
        "            }\n",
        "            const constraints = { video: { width: { ideal: 640 }, height: { ideal: 480 } } };\n",
        "            currentStream = await navigator.mediaDevices.getUserMedia(constraints);\n",
        "            videoElement.srcObject = currentStream;\n",
        "            videoElement.onloadedmetadata = () => {\n",
        "                if (!videoElement) return;\n",
        "                hiddenCanvasForCapture = document.createElement('canvas');\n",
        "                hiddenCanvasForCapture.width = videoElement.videoWidth;\n",
        "                hiddenCanvasForCapture.height = videoElement.videoHeight;\n",
        "                statusDiv.textContent = 'Status: Camera ON. Click \"Capture & Detect\".';\n",
        "                captureButton.disabled = false;\n",
        "                stopButton.disabled = false;\n",
        "                console.log(\"JS: Camera started. Hidden canvas ready for captures.\");\n",
        "            };\n",
        "            videoElement.onerror = (e) => {\n",
        "                console.error(\"JS Video Error:\", e);\n",
        "                statusDiv.textContent = 'Status: Video element error. ' + (e.message || '');\n",
        "            };\n",
        "        } catch (err) {\n",
        "            console.error(\"JS Error accessing camera: \", err);\n",
        "            statusDiv.textContent = 'Status: ERROR - Could not access camera. ' + err.message;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    function stopCameraAndCleanupInternal() {\n",
        "        console.log(\"JS: stopCameraAndCleanupInternal called.\");\n",
        "        if (currentStream) {\n",
        "            currentStream.getTracks().forEach(track => track.stop());\n",
        "            currentStream = null;\n",
        "        }\n",
        "        if(videoElement) videoElement.srcObject = null;\n",
        "        statusDiv.textContent = 'Status: Camera OFF.';\n",
        "        captureButton.disabled = true;\n",
        "        // stopButton.disabled = true; // Optional\n",
        "        console.log(\"JS: Camera and stream stopped and cleaned up.\");\n",
        "    }\n",
        "\n",
        "    captureButton.onclick = () => {\n",
        "        if (!currentStream || !hiddenCanvasForCapture || videoElement.paused || videoElement.ended || videoElement.readyState < videoElement.HAVE_ENOUGH_DATA) {\n",
        "            statusDiv.textContent = 'Status: Camera not ready or stream ended. Please ensure camera is active.';\n",
        "            console.warn(\"JS: Capture attempted but video not ready.\");\n",
        "            if(!currentStream) startCamera();\n",
        "            return;\n",
        "        }\n",
        "        statusDiv.textContent = 'Status: Capturing frame...';\n",
        "        resultImageElement.src = '';\n",
        "\n",
        "        try {\n",
        "            hiddenCanvasForCapture.getContext('2d').drawImage(videoElement, 0, 0, videoElement.videoWidth, videoElement.videoHeight);\n",
        "            const imageDataUrl = hiddenCanvasForCapture.toDataURL('image/jpeg', 0.9);\n",
        "\n",
        "            statusDiv.textContent = 'Status: Sending frame to Python for detection...';\n",
        "            console.log(\"JS: Calling Python 'colab_detect_emotion_callback'.\");\n",
        "\n",
        "            google.colab.kernel.invokeFunction(\n",
        "                'colab_detect_emotion_callback',\n",
        "                [imageDataUrl],\n",
        "                {}\n",
        "            ).then(response => {\n",
        "                console.log(\"JS: Python function 'colab_detect_emotion_callback' acknowledged.\");\n",
        "            }).catch(err => {\n",
        "                console.error(\"JS Error calling Python function: \", err);\n",
        "                statusDiv.textContent = 'Status: ERROR communicating with Python: ' + err.message;\n",
        "            });\n",
        "        } catch (err) {\n",
        "            console.error(\"JS Error during frame capture/URL creation: \", err);\n",
        "            statusDiv.textContent = 'Status: ERROR during capture: ' + err.message;\n",
        "        }\n",
        "    };\n",
        "\n",
        "    stopButton.onclick = stopCameraAndCleanupInternal;\n",
        "\n",
        "    window.colabApp = {\n",
        "        updateResult: (imageDataB64, message) => {\n",
        "            console.log(\"JS: updateResult called by Python. Message: \" + message);\n",
        "            if(resultImageElement) resultImageElement.src = imageDataB64;\n",
        "            if(statusDiv) statusDiv.textContent = \"Status: \" + message;\n",
        "        },\n",
        "        displayError: (errorMessage) => {\n",
        "            console.error(\"JS: displayError called by Python: \" + errorMessage);\n",
        "            if(statusDiv) statusDiv.textContent = \"Status: PYTHON ERROR - \" + errorMessage;\n",
        "        },\n",
        "        stopCameraAndCleanup: stopCameraAndCleanupInternal\n",
        "    };\n",
        "\n",
        "    startCamera();\n",
        "\n",
        "})();\n",
        "''')\n",
        "display(js_ui_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "U2nBmCjc4WLr",
        "outputId": "a2b7c5a3-ed25-4625-81c5-cc7ec0ac8852"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Javascript' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3277265261.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# CELL 4: JAVASCRIPT UI FOR INTERACTIVE DETECTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m js_ui_code = Javascript('''\n\u001b[0m\u001b[1;32m      4\u001b[0m (function() { // IIFE to avoid polluting global scope and allow re-runs\n\u001b[1;32m      5\u001b[0m     \u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JS: Initializing Interactive Emotion Detection UI...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Javascript' is not defined"
          ]
        }
      ]
    }
  ]
}